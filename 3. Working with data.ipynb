{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Working with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:wheat\">\n",
    "<strong>Goal of this notebook.</strong>\n",
    "<ul style=\"margin-top: 0px\">\n",
    "<li>Get used to the standard ways of thinking about data, _data frames_ and _indexed arrays_</li>\n",
    "<li>Learn how to use the <a href=\"http://pandas.pydata.org/\">Pandas</a> library to handle data</li>\n",
    "<li>See some more advanced plotting with <a href=\"https://matplotlib.org/\">matplotlib</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Preamble\n",
    "\n",
    "At the top of almost every piece of data-oriented scientific computing work, we'll import these standard modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules, and give them short aliases so we can write e.g. np.foo rather than numpy.foo\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# The next line is a piece of magic, to let plots appear in our Jupyter notebooks\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The running example for this section is a dataset of stop-and-search records, [made available](https://data.police.uk/data/) by the UK home office. It's a large file, 172MB, so I like to download it to disk, so it's fast to read it each time I restart the notebook. Here's how we can fetch a file from a url, using the Unix command-line tool `wget`. (The exclamation mark is called a _Jupyter magic_, and it means \"Treat this line as though it were executed at the command prompt\". In IB _Unix Tools_ you'll learn more about the Unix command line.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a unix command to download a file (if it's not already downloaded), and show download progress\n",
    "!if [ -e \"stop-and-search.csv\" ]; then echo \"file already downloaded\"; else wget \"https://teachingfiles.blob.core.windows.net/founds/stop-and-search.csv\"; fi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 What data looks like<span id=\"dataframes\"></span>\n",
    "\n",
    "We almost always work with data in the form of a spreadsheet-like table, often referred to as a _data frame_. Here's how to load a dataframe from a file and inspect it. (This dataframe will be used as a running example in the rest of this section of notes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 808101 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Date</th>\n",
       "      <th>Part of a policing operation</th>\n",
       "      <th>Policing operation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age range</th>\n",
       "      <th>Self-defined ethnicity</th>\n",
       "      <th>Officer-defined ethnicity</th>\n",
       "      <th>Legislation</th>\n",
       "      <th>Object of search</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Outcome linked to object of search</th>\n",
       "      <th>Removal of more than just outer clothing</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>police_force</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person search</td>\n",
       "      <td>2014-07-31T23:20:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.938234</td>\n",
       "      <td>-1.388559</td>\n",
       "      <td>Male</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Asian or Asian British - Pakistani (A2)</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Misuse of Drugs Act 1971 (section 23)</td>\n",
       "      <td>Controlled drugs</td>\n",
       "      <td>Nothing found - no further action</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Person search</td>\n",
       "      <td>2014-07-31T23:30:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.912978</td>\n",
       "      <td>-1.431990</td>\n",
       "      <td>Male</td>\n",
       "      <td>over 34</td>\n",
       "      <td>White - White British (W1)</td>\n",
       "      <td>White</td>\n",
       "      <td>Misuse of Drugs Act 1971 (section 23)</td>\n",
       "      <td>Controlled drugs</td>\n",
       "      <td>Suspect summonsed to court</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Person search</td>\n",
       "      <td>2014-07-31T23:45:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.005612</td>\n",
       "      <td>-1.497576</td>\n",
       "      <td>Male</td>\n",
       "      <td>10-17</td>\n",
       "      <td>White - White British (W1)</td>\n",
       "      <td>White</td>\n",
       "      <td>Misuse of Drugs Act 1971 (section 23)</td>\n",
       "      <td>Controlled drugs</td>\n",
       "      <td>Nothing found - no further action</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>hampshire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Type                       Date Part of a policing operation  \\\n",
       "0  Person search  2014-07-31T23:20:00+00:00                          NaN   \n",
       "1  Person search  2014-07-31T23:30:00+00:00                          NaN   \n",
       "2  Person search  2014-07-31T23:45:00+00:00                          NaN   \n",
       "\n",
       "   Policing operation   Latitude  Longitude Gender Age range  \\\n",
       "0                 NaN  50.938234  -1.388559   Male     25-34   \n",
       "1                 NaN  50.912978  -1.431990   Male   over 34   \n",
       "2                 NaN  51.005612  -1.497576   Male     10-17   \n",
       "\n",
       "                    Self-defined ethnicity Officer-defined ethnicity  \\\n",
       "0  Asian or Asian British - Pakistani (A2)                     Asian   \n",
       "1               White - White British (W1)                     White   \n",
       "2               White - White British (W1)                     White   \n",
       "\n",
       "                             Legislation  Object of search  \\\n",
       "0  Misuse of Drugs Act 1971 (section 23)  Controlled drugs   \n",
       "1  Misuse of Drugs Act 1971 (section 23)  Controlled drugs   \n",
       "2  Misuse of Drugs Act 1971 (section 23)  Controlled drugs   \n",
       "\n",
       "                             Outcome Outcome linked to object of search  \\\n",
       "0  Nothing found - no further action                                NaN   \n",
       "1         Suspect summonsed to court                                NaN   \n",
       "2  Nothing found - no further action                                NaN   \n",
       "\n",
       "  Removal of more than just outer clothing  year  month police_force  \n",
       "0                                      NaN  2014      8    hampshire  \n",
       "1                                      NaN  2014      8    hampshire  \n",
       "2                                      NaN  2014      8    hampshire  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import a dataframe using the pandas library\n",
    "stopsearch = pandas.read_csv('stop-and-search.csv')\n",
    "\n",
    "# How many rows are there?\n",
    "print(\"This dataset has\", len(stopsearch), \"rows\")\n",
    "# Display the first 3 rows. iloc[:3] means \"select the first three rows\"\n",
    "stopsearch.iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe is a collection of named columns. Each column has the same length, and all entries in a column have the same type, though different columns may have different types. If you have taken IA/IB _Databases_, you'll see that dataframes are similar to tables in a relational database. There are some differences:\n",
    "* Scientific data is best thought of as logs of observations. Observed facts cannot be unobserved, so UPDATE and DELETE database operations are irrelevant, as are questions about database consistency.\n",
    "* A dataframe has ordered rows, like a matrix, whereas a relation is unordered. (The output of an SQL query can be ordered, therefore it's not a relation.)\n",
    "* We are often given messy badly structued data to work with; and we often create dataframes on the fly, work with them for a while, then discard them. There is rarely a phase of entity-relationship modeling: instead we learn how to think about a dataset by working with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, there are several choices about how to represent dataframes. A simple choice is as a dictionary of lists:\n",
    "```\n",
    "mydata = {'police_force': ['hampshire', 'hampshire', 'hampshire', ...],\n",
    "          'Age range': ['25-34', 'over 34', '10-17', ...],\n",
    "          'year': [2014, 2014, 2014, ...],\n",
    "          ...}\n",
    "```\n",
    "We will instead use the [Pandas](http://pandas.pydata.org/) library, designed specifically for working with data. It has several benefits:\n",
    "\n",
    "* Data import and export has lots of fiddly corner cases. Even printint a dataframe takes a surprisingly large amount of code to do well.\n",
    "* For fast numerical computation and concise code, `numpy` is best as we saw in [&sect;2](2.%20Numerical%20computation.ipynb). Pandas stores dataframe columns as `numpy` vectors.\n",
    "* Some simple operations, like selecting a subset of rows, takes a lot of boilerplate code if implemented in pure Python. Much better to use a Pandas dataframe, which lets us write e.g. `stopsearch[:3]` to automatically apply the row selection to each of the columns.\n",
    "\n",
    "It has the disadvantage of being yet another class to learn. It also has some idiosyncratic notation for indexing, which in my experience can lead to\n",
    "rather cryptic error messages when plotting, and which will be covered in [&sect;3.2](#indexing). It has poor support for missing values in data, which it inherits from `numpy`. Despite these problems, it's the best choice at this stage in Python's evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Importing, exporting, and creating dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very easy to import data from a simple comma-separated value (CSV) file. A CSV file looks like this:\n",
    "\n",
    ">```\n",
    ">\"Sepal.Length\",\"Sepal.Width\",\"Petal.Length\",\"Petal.Width\",\"Species\"\n",
    ">5.1,3.5,1.4,0.2,\"setosa\"\n",
    ">4.9,3,1.4,0.2,\"setosa\"\n",
    ">4.7,3.2,1.3,0.2,\"setosa\"\n",
    ">4.6,3.1,1.5,0.2,\"setosa\"\n",
    ">5,3.6,1.4,0.2,\"setosa\"\n",
    ">```\n",
    "\n",
    "i.e. a header line, then one line per row of the data frame, with values separated by commas.\n",
    "We've already seen how to import a CSV, using [`pandas.read_csv`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).\n",
    "If your file is nearly a CSV but has some quirks such as comments or a missing header row, experiment with the 55 options in [`pandas.read_csv`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).\n",
    "\n",
    "We can use the same function to read CSV files from remote urls (though if you're using Azure Notebooks, be aware that Azure only permits you to connect to Azure web servers.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request  # standard Python library for url requests\n",
    "iris = pandas.read_csv(urllib.request.urlopen('https://teachingfiles.blob.core.windows.net/scicomp/iris.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experience, around 70% of the time you spend working with data will be fighting to import it and clean it up. See\n",
    "[&sect;A3. Data import and cleanup](A.%20Data%20import%20and%20cleanup.ipynb) for a collection of recipes for web scraping, reading from a database, and parsing log files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write a CSV file,\n",
    "```\n",
    "iris.to_csv('iris.csv', index=False)\n",
    "```\n",
    "If you're running this notebook with Azure Notebooks, you would then use the `Data | Download` menu to download the file from Azure Notebooks to your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a dataframe from scratch, pass in a dictionary of columns. Python dictionaries are unordered, so you can optionally specify the column order you want with the `columns` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pandas.DataFrame({'species': ['setosa', 'virginica', 'virginica', 'setosa', 'versicolor'],\n",
    "                         'Petal.length': [1.0, 5.0, 5.8, 1.7, 4.2],\n",
    "                         'Petal.width': [0.2, 1.9, 1.6, 0.5, 1.2]},\n",
    "                        columns = ['species', 'Petal.length', 'Petal.width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can create a dataframe from a list of tuples. Now the `columns` argument is needed to say what the names are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pandas.DataFrame([('setosa', 1.0, 0.2), ('virginica', 5.0, 1.9), ('virginica', 5.8, 1.6), ('setosa', 1.7, 0.5), ('versicolor', 4.2, 1.2)],\n",
    "                        columns = ['species', 'Petal.length', 'Petal.width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe behaves like a dictionary of vectors, and you can add and remove columns using the same syntax you'd use for dictionaries. When you add new columns, Pandas converts them to `numpy` vectors for you, so you can use the usual `numpy` operations. (The columns aren't actually plain `numpy` vectors, as [&sect;3.3](#indexing) explains, and the difference will bite you whenever you try to subset a column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()                                                # what column names are present?\n",
    "iris['Sepal.length'] = [4.6, 6.3, 7.2, 5.1, 5.7]           # add a column\n",
    "if 'Petal.width' in iris: del iris['Petal.width']          # delete a column (if present)\n",
    "iris['P/S'] = iris['Petal.length'] / iris['Sepal.length']  # vectorized whole-column operation\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Selecting from a dataframe\n",
    "Dataframes have a triple identity: part array, part database table, part dictionary. Because of this, there are several ways to select subsets of rows and columns.\n",
    "\n",
    "Selecting columns is easy. We've already seen how to select one column. To select several columns,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select three columns, and print out the first 5 rows of the resulting dataframe\n",
    "stopsearch[['Date', 'Object of search', 'Legislation']].iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select subsets of rows by row number use `iloc[row_indexes]`. This can take any slice or list of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopsearch.iloc[:3]       # the first 3 rows; stopsearch[:3] is an abbreviation for this\n",
    "stopsearch.iloc[[0,3,5]]  # select several rows, by providing a list of row numbers\n",
    "stopsearch.iloc[[5]]      # select a dataframe object consisting of just one row\n",
    "stopsearch.iloc[:3][['Date', 'Object of search']]  #first a row selector, then a column selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select subsets of rows by a boolean vector use `loc[rows_indicator]` where `rows_indicator` is a boolean vector as long as the dataframe. You can optionally also specify a list of columns to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wantcols = ['Date', 'Object of search', 'Outcome']\n",
    "wantrows = stopsearch['police_force'] == 'cambridgeshire'  # a boolean vector\n",
    "stopsearch.loc[wantrows, wantcols][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a third way to select rows from a dataframe, which in my experience is the source of endless confusion. \n",
    "We won't be using it in this course, but it's worth knowing it exists so you can understand the cryptic errors and error messages you will undoubtedly come across.\n",
    "\n",
    "When you see a Pandas dataframe printed out, there is a column at the left printed in bold. These aren't row numbers, they are _row indexes_, which behave like the keys in a dictionary. (In all the examples we've seen so far the indexes happen to be row numbers, but they could be any other Python object.) Pandas remembers row indexes, even when you pull out a single column, and it always tries to match indexes. This is usually not what we want.\n",
    "\n",
    "<span style=\"background-color: red; color:white; padding:2pt; margin-right:.5ex\">\n",
    "Always use <code style=\"background-color:red; color:white\">.values</code> when you are working with subsets of rows.\n",
    "</span>\n",
    "This gives you the actual `numpy` vector behind the column, not the confusing Pandas vector-plus-index object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame({'x': [3,3,4,8,2,7,6]})\n",
    "\n",
    "# This looks like it's adding [3,3,4,8] and [8,2,7,6] -- but it's not!\n",
    "df['x'][:4] + df['x'][-4:]\n",
    "\n",
    "# This is the way to do it\n",
    "df['x'][:4].values + df['x'][-4:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Tabulations and indexed arrays\n",
    "The pattern behind much data processing is split-apply-combine-join: split your data into pieces, apply a transformation to each piece, combine the pieces, and join results from different datasets together. We could code this explicitly with a `for` loop, but it would involve lots of boilerplate code &mdash; and I hope you have been persuaded by [&sect;2](2.%20Numerical%20computation.ipynb) that `for` loops are considered harmful. Instead, let's see how to do it with Pandas.\n",
    "\n",
    "The following line of code splits the data into a separate dataframe for each combination of officer-defined ethnicity and gender, applies the `len` function to each sub-dataframe to get the number of rows it contains, and combines the results into a single indexed array. (For this course, we will only `apply` functions that return simple Python values; it's [more complicated](http://pandas.pydata.org/pandas-docs/stable/groupby.html) to apply functions that return dataframes or indexed arrays.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stopsearch.groupby(['Officer-defined ethnicity', 'Gender']).apply(len)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command has produced an _indexed array_.\n",
    "An indexed array is similar to a normal `numpy` array. It can be indexed using `[]`, but now the indexes aren't integer positions, they're values from the underlying column. Also, the array might be 'incomplete'; in this case there is no entry for `['Mixed','Other']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Asian']             # select one 'row' (i.e. one value in dimension 1, all values in dimension 2)\n",
    "x[:, 'Other']          # select an entire 'column' (i.e. all values in dimension 1, one value in dimension 2)\n",
    "x[['Mixed','White']]   # select two 'rows' (i.e. two values in dimension 1, all values in dimension 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pretty-print an indexed array, use [`unstack()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unstack.html). It will by default fill in any missing values with `NaN` (not a number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[['Mixed','White']].unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert an indexed array to a regular dataframe, use `reset_index`. You can tell it what name to use for the values in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[['Mixed','White']].reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are two basic ways to store data in Pandas, dataframes and indexed arrays, and the skill in working with data is knowing which representation works best for your task.\n",
    " What I'm calling an indexed array, Pandas calls a [multi-indexed](https://pandas.pydata.org/pandas-docs/stable/advanced.html) [`Series`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html).\n",
    "If you get deeper into working with data, you will learn that Pandas blurs the boundary between dataframes and indexed arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Tabulate an existing column of a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Find the most frequent value in a column.\n",
    "```\n",
    "def mode(x):\n",
    "    vals,counts = np.unique(z, return_counts=True)\n",
    "    return vals[np.argmax(counts)]\n",
    "\n",
    "# Take the subset of rows where Age range is not missing\n",
    "df = stopsearch.loc[~pandas.isnull(stopsearch['Age range'])]\n",
    "# Group the dataframe by ethnicity, select the Age range column, and apply our function\n",
    "df.groupby(['Officer-defined ethnicity', 'Gender']).apply(lambda df: mode(df['Age range']))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Joining datasets\n",
    "Suppose we want to know the fraction of stop-and-search suspects for which the search turned up something suspicious. This can be achieved by simply tallying the `Outcome` column of the dataframe. But what if we want to break this number down by ethnicity, to look for evidence of racial bias? We could do this with a `for` loop, looking at each ethnic group in turn &mdash; but `for` loops are considered harmful, and a better way to do it is by combining tables, as follows. (This is the equivalent of `JOIN` in SQL, which you learn about in IA/IB _Databases_.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'Outcome' column has lots of possible values. Let's simplify it to just two.\n",
    "stopsearch['outcome'] = np.where(stopsearch['Outcome'] == 'Nothing found - no further action', 'nothing', 'find')\n",
    "\n",
    "# Create a table of the number of rows for each ethnicity : outcome\n",
    "x = stopsearch.groupby(['Officer-defined ethnicity', 'outcome']).apply(len).reset_index(name='n')\n",
    "# Create a table of the number of rows for each ethnicity\n",
    "y = x.groupby('Officer-defined ethnicity')['n'].apply(sum).reset_index(name='ntot')\n",
    "\n",
    "# Merge the two tables\n",
    "z = x.merge(y, on='Officer-defined ethnicity')\n",
    "\n",
    "# Compute the ratio n/ntot, and display percent_find for each ethnicity\n",
    "z['percent_find'] = z['n'] / z['ntot'] * 100\n",
    "z.loc[z['outcome']=='find', ['Officer-defined ethnicity','percent_find']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to join indexed arrays on their common indices, and that would be a more natural way to write the calculation above, but that counts as advanced Pandas usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Approaching a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                        808101\n",
       "unique                       385633\n",
       "top       2015-05-23T23:00:00+00:00\n",
       "freq                            463\n",
       "Name: Date, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopsearch['Date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.914298055555555"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r'\\d\\d\\d\\d-\\d\\d-\\d\\dT(\\d\\d):(\\d\\d):(\\d\\d(\\.\\d+)?)\\+00:00')\n",
    "def as_hour(s):\n",
    "    m = pattern.match(s)\n",
    "    return int(m.group(1)) + int(m.group(2))/60 + float(m.group(3))/3600 if m else np.nan\n",
    "as_hour('2015-03-31T23:54:51.473000+00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Date</th>\n",
       "      <th>Part of a policing operation</th>\n",
       "      <th>Policing operation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age range</th>\n",
       "      <th>Self-defined ethnicity</th>\n",
       "      <th>Officer-defined ethnicity</th>\n",
       "      <th>Legislation</th>\n",
       "      <th>Object of search</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Outcome linked to object of search</th>\n",
       "      <th>Removal of more than just outer clothing</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>police_force</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Type, Date, Part of a policing operation, Policing operation, Latitude, Longitude, Gender, Age range, Self-defined ethnicity, Officer-defined ethnicity, Legislation, Object of search, Outcome, Outcome linked to object of search, Removal of more than just outer clothing, year, month, police_force, hour]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopsearch['hour'] = np.vectorize(as_hour)(stopsearch['Date'])\n",
    "stopsearch.loc[np.isnan(stopsearch['hour'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    808101.000000\n",
       "mean         14.211017\n",
       "std           7.308990\n",
       "min           0.000000\n",
       "25%          10.400000\n",
       "50%          15.750000\n",
       "75%          20.183333\n",
       "max          23.999444\n",
       "Name: hour, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopsearch['hour'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,  10.4       ,  15.75      ,  20.18333333,  23.99944444])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(stopsearch['hour'], q=[0,25,50,75,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAD8CAYAAAC/1zkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44ee165f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(stopsearch['hour'], bins=30)\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     759820\n",
       "unique         5\n",
       "top        18-24\n",
       "freq      292998\n",
       "Name: Age range, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopsearch['Age range'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAERCAYAAACkWKo8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZsU5fMzMrLj/AUhdacxdyEDEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44d0865da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vs,ns = np.unique(stopsearch['Age range'].astype(str), return_counts=True)\n",
    "xs = np.arange(len(vs))\n",
    "plt.bar(xs, ns, align='center')\n",
    "plt.xticks(xs, vs, rotation=-30, ha='left')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292998</td>\n",
       "      <td>18-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180725</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150286</td>\n",
       "      <td>10-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count  value\n",
       "1  292998  18-24\n",
       "2  180725  25-34\n",
       "0  150286  10-17"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame({'value':vs, 'count':ns}).iloc[np.argsort(ns)[::-1]][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Wrangling a dataset\n",
    "\n",
    "* Number stopped, number find on each day of the week: bar chart with std.err. Exploding, grouping, bar chart & errors\n",
    "* Stopped and found histograms, one plot per day of the week. Facet, plot grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.astype(int) etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Numerical data<a name=\"numerical\"></a>\n",
    "After importing the `flood` data frame, and looking at a few sample rows, we'll inspect it more thoroughly. Let's look at the `value` column. The sample rows suggest that it's numerical, and we can verify this by checking its type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood['value'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick way to get a sense of the distribution is to find its percentiles, e.g. the 25 %ile is what you get if you sort the numbers from lowest to highest and look 25% of the way along. Numpy has a function [`np.percentile`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.percentile.html) for this, and also [`np.nanpercentile`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.nanpercentile.html) which removes NaN (\"not a number\") items first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanpercentile(flood['value'], q=[0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, `res.stats.summary` computes these percentiles, and also shows the mean (computed by [`np.nanmean`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.nanmean.html) to remove NaNs first) and the count of how many NaNs there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(flood['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can show the distribution of values with a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = flood['value']\n",
    "x = x[~np.isnan(x)]    # plt.hist needs us to remove NaN values first\n",
    "plt.hist(x, bins=30)\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Categorical data<a name=\"categorical\"></a>\n",
    "Let's look at another column, `flood['town']`, which is not numerical. Let's see the most frequent values and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs,ns = np.unique(flood['town'], return_counts=True)  # the unique items, and the count of each\n",
    "i = np.argsort(-ns)[:5]                                # the indexes of up to 5 items with the highest counts\n",
    "np.vstack([vs[i], ns[i]]).T                            # show one column for these items, and one for the counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, `res.stats.summary` does this tabulation (and also prints out how many further items there are, if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(flood['town'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can show the distribution of values with a histogram. We have to do the counting ourselves then draw bars with \n",
    "[`matplotlib.pyplot.bar`](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.bar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs,ns = np.unique(flood['town'], return_counts=True)\n",
    "xs = np.arange(len(vs))                               # pick x-coordinates 0, 1, ..., len(vs)-1\n",
    "plt.bar(xs, ns, align='center')                       # use width=... to set the bar width\n",
    "plt.xticks(xs, vs, rotation=-30, ha='left')           # label the x-coordinates of the bars\n",
    "plt.ylabel('count')\n",
    "plt.title('label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Splitting numbers into categories<a name=\"cut\"></a>\n",
    "Sometimes it's useful to simplify a numerical column by splitting it into categories, e.g. bottom third, middle third, top third. We can find the breakpoints with [`np.percentile`](https://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.percentile.html), and find the categories with [`np.digitize`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.digitize.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each measurement station has its own 'low' and 'high' ranges.\n",
    "# Let's normalize the values, so that low=0 and high=1, and categorize these normalized values.\n",
    "x = (flood['value'] - flood['low']) / (flood['high'] - flood['low'])\n",
    "\n",
    "# np.digitize returns integers saying which bin each number falls in.\n",
    "# We'll cast it to be a string, so that summary() displays it as categorical.\n",
    "y = np.digitize(x, bins=np.nanpercentile(x, [100/3, 200/3]))\n",
    "summary(y.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bothersomely, `np.digitize` lumps NaNs into the highest bin, which is misleading. For convenience, `res.stats.cut` takes care of NaNs, and it also gives more helpful labels to the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(cut(x, breaks=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.cut(x, bins=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:wheat\"><strong>Excercise.</strong>\n",
    "The <code style=\"background-color:wheat\">cut</code> function uses \n",
    "<code style=\"background-color:wheat\">np.nanpercentile</code> to split the data into equal percentile ranges.\n",
    "So why are the counts not equal?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Geographic data<a name=\"geo\"></a>\n",
    "This data frame has columns `lat` and `lng` which are likely map coordinates. Matplotlib does have routines for map plots (see the [example gallery](https://matplotlib.org/basemap/users/examples.html)), and there are also many contributed libraries of varying quality. Here is a quick and dirty plot on top of Google Maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; color:white\">\n",
    "TODO: make sure this output works reliably! Do I need my own maps API token? Different plotting library?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy Record Array, with one record for each (lat,lng) pair\n",
    "latlngs = np.rec.fromarrays([flood['lat'], flood['lng']], names=['lat','lng'])\n",
    "# Count the number of flood readings for each unique (lat,lng)\n",
    "vs, ns = np.unique(latlngs, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install gmplot -q                            # install a library for Google Map plots\n",
    "import gmplot\n",
    "import IPython.display                              # allows Python code to show html in the notebook\n",
    "\n",
    "gmap = gmplot.GoogleMapPlotter(52.212, 0.1208, 12)  # define the center of the view, and the zoom level\n",
    "for lat,lng,n in zip(vs.lat, vs.lng, ns):           # add circles at every (lat,lng) pair  \n",
    "    gmap.circle(lat, lng, n/10)                     # (though these are too small for a zoomed-out map)\n",
    "\n",
    "gmap.draw('res/map.html')\n",
    "IPython.display.IFrame(src='res/map.html', width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Grouped statistics<a name=\"groupby\"></a>\n",
    "So far we've only looked at one column at a time. Let's now turn to the relationship between columns (also known as [multivariate analysis](https://en.wikipedia.org/wiki/Multivariate_statistics), as opposed to the univariate analysis we've seen so far). For example, what's the typical range of water levels (`value`) at each measurement station (`label`)? To find this, we need to group the rows of the dataframe, one row for each value of `label`, and for each group we'll compute the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'label':[], 'n':[], 'mean':[], 'sd':[]}\n",
    "for lbl in np.unique(flood['label']):\n",
    "    i = flood['label'] == lbl\n",
    "    res['label'].append(lbl)\n",
    "    res['n'].append(np.count_nonzero(i))\n",
    "    res['mean'].append(np.nanmean(flood['value'][i]))\n",
    "    res['sd'].append(np.nanstd(flood['value'][i]))\n",
    "\n",
    "# Bar plot, with error bars\n",
    "xs = np.arange(len(res['label']))\n",
    "plt.bar(xs, res['mean'], align='center', facecolor='wheat')\n",
    "plt.errorbar(xs, res['mean'], yerr=res['sd'], linestyle='None', ecolor='k')\n",
    "plt.xticks(xs, res['label'], rotation=-30, ha='left')\n",
    "plt.ylabel('value')\n",
    "plt.title('Mean and standard deviation of water levels at each station')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:wheat\"><strong>Exercise.</strong>\n",
    "Implement the above code more efficiently, using vectorized operations rather than a <code style=\"background-color:wheat\">for</code> loop. Hint: <a href=\"https://stackoverflow.com/a/23271510\">stackoverflow.com/a/23271510</a>.\n",
    "What is the complexity of the above code in terms of <em>n</em>, the length of the vector, and <em>k</em>, the number of unique levels?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.8 Facet plots<a name=\"facet\"></a>\n",
    "To show more details at each measurement station, we can split the plot out into many subplots, one per station. This is called a _facet plot_ or a _panel plot_ or a _small multiples_ plot. [According to the plotting guru Edward Tufte](https://en.wikipedia.org/wiki/Small_multiple),\n",
    "<blockquote>\n",
    "At the heart of quantitative reasoning is a single question: Compared to what? Small multiple designs, multivariate and data bountiful, answer directly by visually enforcing comparisons of changes, of the differences among objects, of the scope of alternatives. For a wide range of problems in data presentation, small multiples are the best design solution.\n",
    "</blockquote>\n",
    "\n",
    "This code uses [`fig.add_subplot`](https://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure.add_subplot) to add panels one by one, for each level of `flood['label']`. If we had wanted a two dimensional grid of subplots, split by the levels of two categorical columns, we could have used [`plt.subplots(...)`](https://matplotlib.org/examples/pylab_examples/subplots_demo.html) to create the full grid of panels in one go, as in\n",
    "[these demos](https://matplotlib.org/examples/pylab_examples/subplots_demo.html).\n",
    "\n",
    "Previously we have used commands like `plt.hist()` to draw histograms, but this code uses `ax.hist()` where `ax` is an `Axes` object. All the plotting routines are actually [`Axes` methods](https://matplotlib.org/api/axes_api.html), and the `plt.*` methods are just aliases. When you look for code snippets on the web, you'll find both styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_value = (flood['value'] - flood['low']) / (flood['high'] - flood['low'])\n",
    "labels = np.unique(flood['label'])\n",
    "\n",
    "fig = plt.figure()\n",
    "for i,lbl in enumerate(labels):\n",
    "    ax = fig.add_subplot(3, 3, i+1)        # numrows=3, numcols=3, new subplot in the (i+1)th position\n",
    "    x = norm_value[flood['label'] == lbl]\n",
    "    x = x[~np.isnan(x)]                    # remove NaN values since ax.hist doesn't work with them\n",
    "    ax.hist(x)\n",
    "    ax.set_title(lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the plot look lovely, we need some plot-tweaking.\n",
    "\n",
    "* `fig.add_subplot` lets us [specify axes to be shared](https://matplotlib.org/users/recipes.html). The code below makes all the subplots share the same x axis as the top left subplot.\n",
    "\n",
    "* Since all the subplots share the same x axis, but the data for each plot is different, `ax.hist` will choose different bins for each subplot. It looks better to force them all to use the same bins.\n",
    "\n",
    "* Use `plt.get_cmap(name, n)` to get a colour map with `n` values, where `name` is one of the [standard colour-map names](https://matplotlib.org/users/colormaps.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(flood['label'])\n",
    "norm_value = (flood['value'] - flood['low']) / (flood['high'] - flood['low'])\n",
    "bins = np.linspace(min(norm_value), max(norm_value), 40)\n",
    "\n",
    "with matplotlib.rc_context({'figure.figsize': [10,6], 'figure.subplot.hspace': 0.3}):\n",
    "    colors = plt.get_cmap('Set2', len(labels))\n",
    "    fig = plt.figure()\n",
    "    ax0 = None\n",
    "    for i,lbl in enumerate(labels):\n",
    "        if ax0 is None:\n",
    "            ax = fig.add_subplot(3, 3, i+1)\n",
    "            ax0 = ax\n",
    "        else:\n",
    "            ax = fig.add_subplot(3, 3, i+1, sharex=ax0)\n",
    "        x = norm_value[flood['label'] == lbl]\n",
    "        x = x[~np.isnan(x)]\n",
    "        ax.hist(x, bins=bins, facecolor=colors(i), edgecolor='0.7')\n",
    "        ax.set_title(lbl)\n",
    "    fig.suptitle('Normalized value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:wheat\"><strong>Exercise.</strong>\n",
    "Which values of <em>i</em> correspond to the three bottom-most panels?\n",
    "Use <code style=\"background-color:wheat\">ax.get_xaxis().set_visible(False)</code> to turn off the ticks on all the other panels, so the panel labels can be read cleanly.\n",
    "<em>Solution: if <code style=\"background-color:wheat\">i + 3 &geq; len(labels)</code> then panel <em>i</em> is bottom-most.</em>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Grouped plots (and timestamps)<a name=\"grouped\"></a>\n",
    "Here's another way to show grouped data. Again we'll plot each measurement station (`label`) separately, but this time we'll plot the water level (`value`) as a function of time (`t`). The lines for each station can happily fit on the same panel, and we'll add a legend.\n",
    "\n",
    "The first step is to fix up the time column, so that `matplotlib` knows it's a timestamp and not just a string, so that it will display nicely. As [xkcd](https://www.xkcd.com/1883/) observes, timestamps are a nuisance because of timezones &mdash; and also because of unequal months and leap years and so on, which make it hard work to get axes right in plots.\n",
    "\n",
    "<a href=\"https://www.xkcd.com/1883/\"><img src=\"https://imgs.xkcd.com/comics/supervillain_plan.png\" style=\"height:30em\" alt=\"supervillain timezone woes\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, pytz\n",
    "x = flood['t']\n",
    "# Parse the timestamp strings (see https://docs.python.org/3/library/datetime.html#datetime.datetime.strptime)\n",
    "x = [datetime.datetime.strptime(tstr, '%Y-%m-%dT%H:%M:%SZ') for tstr in x]\n",
    "# Mark each timestamp as a UTC timestamp\n",
    "# which is what the docs say they are: http://environment.data.gov.uk/flood-monitoring/doc/reference\n",
    "x = [t.replace(tzinfo=pytz.utc) for t in x]\n",
    "# Convert to a local timestamp (which in this case is British Summer Time, one hour off UTC)\n",
    "local_tz = pytz.timezone('Europe/London')\n",
    "x = [t.astimezone(local_tz) for t in x]\n",
    "# Store it in the data frame as a numpy vector, so we can use numpy indexing on it\n",
    "flood['t2'] = np.array(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plotting code below uses the same core logic for splitting by `label` that we've used before. This time, for each level of `label`, we call `ax.plot(x,y,lbl)`. This picks a different colour each time, and it remembers the association between colours and labels, so that `ax.legend()` can draw the right thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(flood['label'])\n",
    "\n",
    "# Set the plot size to be 10x6 nominal inches, for this plot only.\n",
    "# See https://matplotlib.org/users/customizing.html for more customization options.\n",
    "with matplotlib.rc_context({'figure.figsize': [10,6]}):\n",
    "    \n",
    "    fig,ax = plt.subplots()\n",
    "    for lbl in labels:\n",
    "        i = flood['label'] == lbl\n",
    "        t,v = flood['t2'][i], flood['value'][i]\n",
    "        # Sort the readings by time, because otherwise the line could go back and forth across the plot\n",
    "        j = np.argsort(t)\n",
    "        ax.plot(t[j], v[j], linestyle='-', label=lbl)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Date axis tweaking taken from https://matplotlib.org/examples/api/date_demo.html\n",
    "    ax.xaxis.set_major_locator(matplotlib.dates.WeekdayLocator(byweekday=matplotlib.dates.MO, tz=local_tz))\n",
    "    ax.xaxis.set_minor_locator(matplotlib.dates.DayLocator(tz=local_tz))\n",
    "    ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%a %d %b'))\n",
    "    ax.set_ylim(-0.8, 1.1)\n",
    "    ax.grid(True, axis='x', color='0.8')\n",
    "    fig.autofmt_xdate(bottom=0.2, rotation=-30, ha='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is `fig,ax = plt.subplots()` about? The default arguments are [`plt.subplots(nrows=1,ncols=1)`](https://matplotlib.org/api/pyplot_api.html?highlight=matplotlib%20pyplot%20subplots#matplotlib.pyplot.subplots), i.e. it creates a 1&times;1 grid of subplots, and it returns a [`Figure`](https://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure) object and an [`Axes`](https://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes) object. The former has methods for modifying the plot as a whole, and the latter has all the methods for actually plotting data plus methods for tweaking how the axis is shown. When we use `plt.plot()` it's actually just wrapper that retrieves the current axes then calls `ax.plot()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 Cross tabulation<a name=\"crosstab\"></a>\n",
    "Cross tabulation lets us see how two or more categorical variables relate to each other. For example, let's find out how many readings there are in each town, and for each river."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of unique towns, and let itowns[i] be the town that row i of the dataframe belongs to.\n",
    "# Likewise for rivers.\n",
    "towns,itowns = np.unique(flood['town'], return_inverse=True)\n",
    "rivers,irivers = np.unique(flood['river'], return_inverse=True)\n",
    "# Create an empty array with one row per town, one column per river\n",
    "x = np.zeros([len(towns), len(rivers)])\n",
    "# Tally up the number of readings corresponding to each cell of the array.\n",
    "for it,ir in zip(itowns, irivers):\n",
    "    x[it,ir] += 1\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's painful to have to write multiple lines of code every time we want a simple cross tabulation, and the output doesn't show row and column labels. This is where library routines come into their own, specifically \n",
    "[`pandas.crosstab`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.crosstab.html)\n",
    "and [`pivot_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot_table.html) and [`unstack`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack). The `pandas` syntax is powerful but takes some getting used to, so instead here's a simple wrapper function, `res.stats.crosstab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab('town', 'river', data=flood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-tabulation is useful for figuring out the contents of a data set you've been given. Let's work out how many measurement stations there are for each town and each river:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Produce a data frame x with one row per town:river:measure_id.\n",
    "# (crosstab produces a table by default, but with format_='DataFrame' it produces a pandas.DataFrame.)\n",
    "x = crosstab('town','river','measure_id', data=flood, format_='DataFrame')\n",
    "# For each town:river, how many rows does x have i.e. how many measurement stations?\n",
    "crosstab('town', 'river', data=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:wheat\"><strong>Exercise.</strong>\n",
    "(Advanced practice at <code style=\"background-color:wheat\">numpy</code> vectorized coding.)\n",
    "Rewrite the explicit tabulation code, using vectorized operations rather than a <code style=\"background-color:wheat\">for</code> loop.\n",
    "<em>Solution:</em>\n",
    "<pre style=\"background-color:wheat\">\n",
    "idx,ns = np.unique(np.vstack([itowns,irivers]).T, axis=0, return_counts=True)\n",
    "x = np.zeros([len(towns), len(rivers)])\n",
    "x[tuple(idx.T)] = ns\n",
    "</pre>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 Merging dataframes<a name=\"merge\"></a>\n",
    "Consider these two questions about the flood data:\n",
    "\n",
    "* We've seen how to compute the mean and standard deviation of water level at each measurement station. How can we use these to standardize all the readings, per station?\n",
    "* How can we compute the weekly rate of change at each station, i.e. the average value in a week, minus the value in the previous week?\n",
    "\n",
    "These are questions that we can answer by merging dataframes, or `JOIN`ing them as it's referred to in IA _Databases_. \n",
    "It's possible to implement this yourself in plain Python, but there's no reason not to use\n",
    "[`pandas.DataFrame.merge()`](https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging).\n",
    "Here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean and standard deviation per station, as in Section 3.5.\n",
    "stations = {'label':[], 'mean':[], 'sd':[]}\n",
    "for lbl in np.unique(flood['label']):\n",
    "    i = flood['label'] == lbl\n",
    "    stations['label'].append(lbl)\n",
    "    stations['mean'].append(np.nanmean(flood['value'][i]))\n",
    "    stations['sd'].append(np.nanstd(flood['value'][i]))\n",
    "\n",
    "# Do the merge, and (optionally) convert it back to a plain Python dictionary\n",
    "flood2 = pandas.DataFrame(flood).merge(pandas.DataFrame(stations), on='label')\n",
    "flood2 = OrderedDict((k, v.values) for k,v in flood2.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same plotting code as in Section 3.7, but applied to the standardized values `(flood2['value']-flood2['mean'])/flood2['sd']` now looks like this:\n",
    "![standardized water levels](res/normts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:wheat\"><strong>Exercise.</strong>\n",
    "To compute weekly rate of change, what two dataframes should we merge, and what join key should we use? \n",
    "<em>Hint: the join key should be a list of two column names.</em>.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
